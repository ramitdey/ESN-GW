{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f27fe4-81c8-40bd-9a06-756c490b1bc0",
   "metadata": {},
   "source": [
    "# Detection of Gravitational waves using Echo state networks for space based detectors (LISA)\n",
    "\n",
    "In this notebook we intend to build a machine learning based model (using ESN) to detect gravitational waves embedded in colored Gaussian noise generated using the power spectral density of LISA detectors.\n",
    "\n",
    "@author: Ramit Dey, Turmoli Neogi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c27553-5834-4bdc-bc78-564688c74809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.ops import math_ops\n",
    "#from ESN import EchoStateRNNCell\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from scipy.sparse import *\n",
    "from scipy.sparse.linalg import *\n",
    "\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# random numbers\n",
    "random_seed = np.frombuffer(os.urandom(4), dtype=np.uint32)[0]\n",
    "print(\"seed: \", random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4dd29-9dd7-42fd-98fb-e603a1277e36",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ee9c9-fb73-4783-827b-069a24288522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generator for loading the data in batches\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'data generator function for loading the GW waveforms'\n",
    "    \n",
    "    def __init__(self, list_IDs, labels, batch_size=32, n_channels=1,t_len=160000, n_classes=2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.t_len=t_len\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size,self.t_len, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('scratch/LISA noise/ns_' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58dfdb-ef7a-487d-8dd5-b47a205b273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data labels given as targets in the output for training the model\n",
    "\n",
    "ID_list=[i for i in range(0,4000)]\n",
    "\n",
    "\n",
    "#creating labels\n",
    "\n",
    "a=[0 for i in range(0,2000)] #noise\n",
    "\n",
    "b=[1 for i in range(0,2000)] #data\n",
    "\n",
    "#label list\n",
    "\n",
    "label_list=np.concatenate((np.array(a),np.array(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd0dab-4dff-48f3-89ed-cec1a5d059e8",
   "metadata": {},
   "source": [
    "# EMN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f80de-84cb-4963-a73c-c999ec09a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Echo State Network \"\"\"\n",
    "class reservoir_layer(object):\n",
    "\tdef __init__(self, rng, n_in, n_res, IS, SR, sparsity, leakyrate, use_bias=False):\n",
    "\t\tself.n_in = n_in\n",
    "\t\tself.n_res = n_res #\n",
    "\t\tself.IS = IS #Input scaling\n",
    "\t\tself.SR = SR #spectral radius\n",
    "\t\tself.sparsity = sparsity\n",
    "\t\tself.leakyrate = leakyrate\n",
    "\t\tself.use_bias = use_bias\n",
    "\t\tself.W_in = 2*np.array(np.random.random(size=(n_res, n_in)))-1\n",
    "\t\tW_res_temp = sp.sparse.rand(self.n_res, self.n_res, self.sparsity)\n",
    "\t\tvals, vecs = sp.sparse.linalg.eigsh(W_res_temp, k=1)\n",
    "\t\tself.W_res = self.SR * W_res_temp / vals[0]\n",
    "\t\tb_bound = 0.1\n",
    "\t\tself.b = 2*b_bound*np.random.random(size=(self.n_res, 1))-b_bound\n",
    "\n",
    "\n",
    "#function creating the echo states\n",
    "\n",
    "\tdef update_states(self, data, dataset,string):\n",
    "\t\tn_forget_steps = 0\n",
    "\t\tnums_sample = np.shape(data)[0]\n",
    "\t\tnums_frame = np.shape(data)[1]\n",
    "\t\techo_states = np.empty((nums_sample,(nums_frame-n_forget_steps), self.n_res), np.float32)\n",
    "\t\tfor i_sample in range(nums_sample):\n",
    "\t\t\tseries = data[i_sample]\n",
    "\t\t\t#print ('create echo-states of %4d-th %s sample in s'(i_sample, string, dataset))\n",
    "\t\t\tcollect_states = np.zeros((nums_frame-n_forget_steps, self.n_res))\n",
    "\t\t\tx = np.zeros((self.n_res, 1))\n",
    "\t\t\tfor t in range(nums_frame):\n",
    "\t\t\t\t#print (\"sample %03d for %03d th time stamp processed ......\" % (i_sample+1, t+1))\n",
    "\t\t\t\tu_t = np.asarray([series[t,:]]).T\n",
    "\t\t\t\tif self.use_bias:\n",
    "\t\t\t\t\txUpd =  np.tanh(np.dot(self.W_in, self.IS*u_t) + np.dot(self.W_res.toarray(), x) + self.b)\n",
    "\t\t\t\telse:        \n",
    "\t\t\t\t\txUpd =  np.tanh(np.dot(self.W_in, self.IS*u_t) + np.dot(self.W_res.toarray(), x))\n",
    "\t\t\t\tx = (1-self.leakyrate)*x + self.leakyrate*xUpd\n",
    "\t\t\t\tif t >= n_forget_steps:\n",
    "\t\t\t\t\tcollect_states[t-n_forget_steps,:] = x.T\n",
    "\t\t\tcollect_states = np.asarray(collect_states)\n",
    "\t\t\techo_states[i_sample] = collect_states\n",
    "\t\treturn echo_states\n",
    "\n",
    "\n",
    "# create teh echo matrix\n",
    "\n",
    "def run_loading(n_res, IS, SR, SP):\n",
    "\ttrain_x_lst,test_x_lst, train_y, test_y = split\n",
    "\ttrain_x=np.array(train_x_lst)\n",
    " \t\n",
    "\ttrain_x=train_x.reshape(-1,16384,1)\n",
    "\n",
    " \t\n",
    "\ttest_x=np.array(test_x_lst)\n",
    "\ttest_x=test_x.reshape(-1,16384,1)\n",
    "\n",
    " \n",
    " \t#test_x=np.array(test_x)\n",
    "\n",
    "\tnums_train, len_series =  np.shape(train_x)[0], np.shape(train_x)[1]\n",
    "\tnums_test = np.shape(test_x)[0]\n",
    "\trng = np.random.RandomState(1882517)\n",
    "\tn_res = n_res \n",
    "\tIS = IS\n",
    "\tSR = SR\n",
    "\tSP = SP #sparsity\n",
    "\tLK = 1\n",
    "\tescnn = reservoir_layer(rng, n_in=1, n_res=n_res, IS=IS, SR=SR, sparsity=SP, leakyrate=LK, use_bias=False)\n",
    "\ttrain_echoes = escnn.update_states(train_x, dataset_name, 'train')\n",
    "\ttest_echoes = escnn.update_states(test_x, dataset_name, 'test')\n",
    "\treturn train_echoes, train_y, test_echoes, test_y, dataset_name, n_res, len_series, IS, SR, SP \n",
    "\n",
    "\n",
    "def transfer_labels(labels):\n",
    "\tindexes = np.unique(labels)\n",
    "\tnum_classes = indexes.shape[0]\n",
    "\tnum_samples = np.shape(labels)[0]\n",
    "\tfor i in range(num_samples):\n",
    "\t\tnew_label = np.argwhere(indexes == labels[i])[0][0]\n",
    "\t\tlabels[i] = new_label\n",
    "\treturn labels, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909b6095-1232-4b13-996c-5454797d4f5f",
   "metadata": {},
   "source": [
    "## Model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2eac8-9f50-4544-a3cb-e681df7e90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the parameters defining the EMN model\n",
    "\n",
    "number_res=8   #32 #reservoir size\n",
    "IS=0.1\n",
    "SR=0.9\n",
    "SP=0.7\n",
    "nb_epoch =50\n",
    "batch_size=5\n",
    "nb_filter=40  #originally 120\n",
    "# ratio=[0.6,0.7]\n",
    "ratio=[0.2,0.2]\n",
    "\n",
    "nums_class=2 #noise + types of GW present on the data stream\n",
    "dataset_name='GW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa723c4-2e37-44d7-a0fb-32568583f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "train_echoes, train_y, test_echoes, test_y, dataset_name, n_res, len_series, IS, SR, SP = run_loading(n_res =number_res,IS=IS,SR=SR,SP=SP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a86d2-4e57-43f0-bdcb-a6b5fe9de818",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "\n",
    "nb_class = nums_class\n",
    "nb_sample_train = np.shape(train_echoes)[0]\n",
    "nb_sample_test = np.shape(test_echoes)[0]\n",
    "test_data = np.reshape(test_echoes,(nb_sample_test, 1, len_series, n_res))\n",
    "\n",
    "L_train = [x_train for x_train in range(nb_sample_train)]\n",
    "np.random.shuffle(L_train)\n",
    "train_data = np.zeros((nb_sample_train, 1, len_series, n_res))\n",
    "#train_label = np.zeros((nb_sample_train, nb_class))\n",
    "for m in range(nb_sample_train):\n",
    " \ttrain_data[m,0,:,:] = train_echoes[L_train[m],:,:]\n",
    "# \ttrain_label[m,:] = train_y[L_train[m],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80455b-ac2b-4dc4-92e7-85e1c060e9e0",
   "metadata": {},
   "source": [
    "## NN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ddf3c-d002-433c-90ba-d68d908a5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, len_series, n_res)\n",
    "\n",
    "nb_row=[np.int(ratio[0]*len_series),np.int(ratio[1]*len_series)]\n",
    "nb_col = input_shape[2]\n",
    "\n",
    "kernel_initializer = 'lecun_uniform'\n",
    "activation = 'relu'\n",
    "padding = 'valid'\n",
    "strides = (1, 1)\n",
    "data_format='channels_first'\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "loss = ['binary_crossentropy', 'categorical_crossentropy']\n",
    "verbose = 1\n",
    "#model\n",
    "input = Input(shape = input_shape)\n",
    "convs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67c28f-f54c-4b12-9965-049a42943a86",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112d2a1-0a05-414d-843d-778d62a309e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN part of the EMN model\n",
    "\n",
    "for j in range(len(nb_row)):\n",
    "\tconv = Conv2D(nb_filter, (nb_row[j], nb_col), kernel_initializer = kernel_initializer, activation = activation, \n",
    "\tpadding = padding, strides = strides, data_format = data_format)(input)\n",
    "\tconv = GlobalMaxPooling2D(data_format = data_format)(conv)\n",
    "\tconvs.append(conv)\n",
    "    \n",
    "body_feature = concatenate(convs,name='concat_layer')\n",
    "#body_feature = Dense(64, kernel_initializer = kernel_initializer, activation = activation)(body_feature)\n",
    "#body_feature = Dense(128, kernel_initializer = kernel_initializer, activation = activation)(body_feature)\n",
    "body_feature = Dropout(0.4)(body_feature)\n",
    "output = Dense(nb_class, kernel_initializer = kernel_initializer, activation = 'softmax',name = 'dense_output')(body_feature)\n",
    "model = Model(inputs=input, outputs = output)\n",
    "model.summary()\n",
    "model.compile(optimizer = optimizer, loss = loss[1], metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e70053-94d8-4dea-8c5d-faf1022d8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data.tolist(), train_y, batch_size = batch_size, \n",
    "\tepochs = nb_epoch,verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483f6b9-ea94-491f-a65d-99bbb88d5b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b7965c-ddc5-4dcd-82e8-a3d0c570914d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483e11e-d3b2-4374-ab29-ffdb46f7d1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b90ae5-b2d5-437a-8be4-8d3618edb4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
